{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dbb586f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.axes_grid1.inset_locator import inset_axes\n",
    "from tqdm import tqdm\n",
    "\n",
    "from sampler import Sampler\n",
    "from dataset import SQGDataset\n",
    "\n",
    "from diffusion_networks import SongUNet\n",
    "from pathlib import Path\n",
    "import torch.optim as optim\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8388cd85",
   "metadata": {},
   "outputs": [],
   "source": [
    "bs = 10\n",
    "data_std = 2660\n",
    "dataset = SQGDataset(\"data/SQG\", mean=0, std=data_std)\n",
    "\n",
    "loader = torch.utils.data.DataLoader(dataset, batch_size=bs, shuffle=False)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e3643a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "etaz_loss = lambda z0, z1: z0\n",
    "eta1_loss = lambda z0, z1: z1\n",
    "b_loss = lambda z0, z1: z1 - z0 # All the samplers are for b.\n",
    "\n",
    "target_fn = b_loss  # Choose the target function for the loss\n",
    "\n",
    "model = SongUNet(img_resolution=64, in_channels=2, out_channels=2,\n",
    "                embedding_type='fourier', encoder_type='residual', decoder_type='standard',\n",
    "                channel_mult_noise=2, resample_filter=[1, 3, 3, 1], model_channels=32, channel_mult=[2, 2, 2],\n",
    "                attn_resolutions=[32,]\n",
    "                              )\n",
    "\n",
    "def loss_fn(model, batch, target_fn):\n",
    "    z0 = torch.randn_like(batch)\n",
    "    z1 = batch\n",
    "    \n",
    "    t = torch.rand(batch.shape[0], device=batch.device)\n",
    "    zt = (1 - t[:,None, None, None]) * z0 + t[:,None, None, None] * z1\n",
    "    \n",
    "    pred = model(zt, t)\n",
    "    target = target_fn(z0, z1)\n",
    "    loss =  torch.mean(0.5 * pred ** 2 - target * pred) #torch.mean(0.5*(pred - target) ** 2)\n",
    "    \n",
    "    return loss\n",
    "\n",
    "def train(target_fn, device, loader, val_loader):\n",
    "\n",
    "    print(\"Num params: \", sum(p.numel() for p in model.parameters()), flush=True)\n",
    "    result_path = Path('results')\n",
    "    result_path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    learning_rate = 1e-3\n",
    "    weight_decay = 1e-4\n",
    "    num_epochs = 50\n",
    "\n",
    "    optimizer = optim.AdamW(model.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
    "    scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=num_epochs)\n",
    "    warmup_scheduler = optim.lr_scheduler.LinearLR(optimizer, start_factor=0.001, end_factor=1.0, total_iters=1000)\n",
    "\n",
    "    loss_values = []\n",
    "    val_loss_values = []\n",
    "    best_val_loss = float('inf')\n",
    "\n",
    "    # Setup for logging\n",
    "    log_file_path = result_path / f'training_log.csv'\n",
    "    with open(log_file_path, mode='w', newline='') as file:\n",
    "        writer = csv.writer(file)\n",
    "        writer.writerow(['Epoch', 'Average Training Loss', 'Validation Loss'])\n",
    "\n",
    "    # Training loop\n",
    "    for epoch in range(num_epochs):\n",
    "        \n",
    "        # Training phase``\n",
    "        model.train()\n",
    "        total_train_loss = 0\n",
    "        for image in tqdm(loader):\n",
    "            image = image.to(device)\n",
    "            \n",
    "            optimizer.zero_grad()   \n",
    "            loss = loss_fn(model, image, target_fn)\n",
    "            total_train_loss += loss.item()\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()        \n",
    "            warmup_scheduler.step()\n",
    "\n",
    "        avg_train_loss = total_train_loss / len(loader)\n",
    "        \n",
    "        # Validation phase\n",
    "        model.eval()\n",
    "        total_val_loss = 0\n",
    "        with torch.no_grad():\n",
    "            for image in tqdm(loader):\n",
    "                image = image.to(device)\n",
    "                \n",
    "                loss = loss_fn(model, image, target_fn)\n",
    "                total_val_loss += loss.item()\n",
    "                    \n",
    "            avg_val_loss = total_val_loss / len(val_loader)\n",
    "\n",
    "        # Checkpointing\n",
    "        if avg_val_loss < best_val_loss:\n",
    "            best_val_loss = avg_val_loss\n",
    "            torch.save(model.state_dict(), result_path/f'best_model.pth')\n",
    "            \n",
    "        scheduler.step()\n",
    "        \n",
    "        loss_values.append([avg_train_loss])\n",
    "        val_loss_values.append(avg_val_loss)\n",
    "        \n",
    "        with open(log_file_path, mode='a', newline='') as file:\n",
    "            writer = csv.writer(file)\n",
    "            writer.writerow([epoch+1, avg_train_loss, avg_val_loss])\n",
    "        \n",
    "        print(f'Epoch [{epoch+1}/{num_epochs}], Average Loss: {avg_train_loss:.4f}, Validation Loss: {avg_val_loss:.4f}', flush=True)\n",
    "\n",
    "        torch.save(model.state_dict(), result_path/f'final_model.pth')\n",
    "\n",
    "#train(target_fn, device, loader, loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15d0872b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = \"best_model.pth\" # or your trained path\n",
    "image_shape = (2, 64, 64)\n",
    "\n",
    "members = 5\n",
    "\n",
    "eps = lambda t: 0.1 * (1 - t)  # Noise when sampling\n",
    "invert_eps = lambda t: 0. * (1 - t)  # Noise when inverting\n",
    "\n",
    "steps = 100\n",
    "invert_steps = 100\n",
    "\n",
    "debug = True\n",
    "\n",
    "sampler = Sampler(device, members, eps, steps, invert_eps, invert_steps, model_path, debug)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a841790",
   "metadata": {},
   "source": [
    "### Example on how to sample a physical state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "608ba3eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Random noise\n",
    "z0 = torch.randn((members, *image_shape), device=device)\n",
    "\n",
    "## All the same noise for testing epsilon\n",
    "#z0 = torch.randn((1, *image_shape), device=device).repeat(members, 1, 1, 1)\n",
    "\n",
    "z1, _ = sampler.sample(z0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1039bcfb",
   "metadata": {},
   "source": [
    "### Plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "188cfc42",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(2,3, figsize=(9,6))\n",
    "cmap  =  plt.get_cmap('jet') #'jet' #\n",
    "level = 0 # 1\n",
    "\n",
    "def set_cbar(im):\n",
    "    ax = im.axes\n",
    "    # Create an inset axes for the colorbar above the plot\n",
    "    cax = inset_axes(ax,\n",
    "                        width=\"100%\",   # relative to ax width\n",
    "                        height=\"5%\",   # relative to ax height\n",
    "                        loc='upper center',\n",
    "                        bbox_to_anchor=(0, 0.18, 1, 1),  # place above\n",
    "                        bbox_transform=ax.transAxes,\n",
    "                        borderpad=0)\n",
    "    cbar = plt.colorbar(im, cax=cax, orientation='horizontal')\n",
    "    cbar.ax.xaxis.set_ticks_position('top')\n",
    "    cbar.ax.xaxis.set_label_position('top')\n",
    "\n",
    "for i, ax in enumerate(ax.flat):\n",
    "    ax.set_aspect('equal')\n",
    "    ax.imshow((z1.cpu())[i, level], cmap=cmap)\n",
    "    \n",
    "    ax.yaxis.set_visible(False)\n",
    "    ax.xaxis.set_visible(False)\n",
    "plt.tight_layout()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "flowdas",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
