# -*- coding: utf-8 -*-
# PyTorch åŠ é€Ÿç‰ˆï¼šéšæœºå­ç©ºé—´ + Mardia/èƒ½é‡è·ç¦»æ£€éªŒï¼ˆGPU å‹å¥½ï¼‰
import numpy as np
import torch
from torch import Tensor
from torch.distributions import Chi2, Normal, MultivariateNormal
from tqdm import tqdm

DTYPE = torch.float64

def to_device(x, device=None):
    if isinstance(x, np.ndarray):
        t = torch.from_numpy(x)
    elif isinstance(x, torch.Tensor):
        t = x
    else:
        t = torch.as_tensor(x)
    if device is not None:
        t = t.to(device)
    return t.to(DTYPE)

# ------------------------- æ•°æ®è¯»å–ï¼ˆæ²¿ç”¨ä½ çš„ APIï¼‰ -------------------------
class SQGDataTorch:
    def __init__(self, truth_path='SQG.npy', noise_path='inverted_SQG.npy', data_std=2660.0, device=None):
        self.device = device if device is not None else ('cuda' if torch.cuda.is_available() else 'cpu')
        self.truth_raw = to_device(np.load(truth_path), self.device)
        self.noise_raw = to_device(np.load(noise_path), self.device)
        assert self.truth_raw.shape == self.noise_raw.shape, "Truth å’Œ Noise æ•°æ®å½¢çŠ¶ä¸ä¸€è‡´ï¼"

        self.shape = self.truth_raw.shape  # (time, levels, dx, dy)
        self.time, self.levels, self.dx, self.dy = self.shape
        self.data_std = float(data_std)

        self.truth_norm = self.truth_raw / self.data_std
        self.noise_norm = self.noise_raw / self.data_std
        print(f"âœ… SQG æ•°æ®åŠ è½½å®Œæˆ: shape = {self.shape}, data_std = {data_std}, device={self.device}")

    def get_field(self, dataset='noise', t=None, level=0, normalized=False) -> Tensor:
        assert dataset in ['truth', 'noise']
        data_all = (self.truth_norm if normalized else self.truth_raw) if dataset == 'truth' \
                   else (self.noise_norm if normalized else self.noise_raw)
        if t is None:
            return data_all[:, level]           # (T, dx, dy)
        else:
            return data_all[t, level]           # æ”¯æŒ int/list/slice -> (T?, dx, dy)

# ------------------------- å·¥å…·å‡½æ•°ï¼ˆTorch ç‰ˆï¼‰ -------------------------
def _standardize_columns_torch(X: Tensor) -> Tensor:
    # X: (T, D)
    mean = X.mean(dim=0, keepdim=True)
    Xc = X - mean
    sd = Xc.std(dim=0, unbiased=True, keepdim=True)
    sd = torch.where(sd == 0, torch.ones_like(sd), sd)
    return Xc / sd

def _random_orth_subspace_torch(D: int, k: int, generator=None, device=None) -> Tensor:
    # è¿”å› DÃ—k çš„æ­£äº¤åŸºï¼ˆQRï¼‰
    if generator is None:
        G = torch.randn(D, k, dtype=DTYPE, device=device)
    else:
        G = torch.randn(D, k, dtype=DTYPE, device=device, generator=generator)
    Q, _ = torch.linalg.qr(G, mode='reduced')
    return Q[:, :k]

# ------------------------- Mardia å¤šå…ƒæ­£æ€æ£€éªŒï¼ˆTorch æ ¸å¿ƒæé€Ÿï¼‰ -------------------------
@torch.no_grad()
def mardia_test_torch(Y: torch.Tensor, jitter: float = 1e-8) -> dict:
    """
    Y: (T, p)
    è¿”å›: dict(skew_stat, skew_p, kurt_stat, kurt_p)
    """
    T, p = Y.shape
    device = Y.device
    dtype = torch.float64

    mu = Y.mean(dim=0, keepdim=True)                # 1Ã—p
    Z = Y - mu                                      # TÃ—p

    # åæ–¹å·®ï¼ˆä¸ ddof=1 å¯¹é½ï¼‰
    S = (Z.T @ Z) / (T - 1)
    S = S + jitter * torch.eye(p, dtype=dtype, device=device)

    # Cholesky + ä¸‰è§’è§£
    L = torch.linalg.cholesky(S)                    # pÃ—p
    W = torch.linalg.solve_triangular(L, Z.T, upper=False)  # pÃ—T

    # A = W^T W
    A = W.T @ W                                     # TÃ—T

    # b1p = (1/T^2) * sum A^3
    b1p = A.pow(3).sum() / (T**2)

    # d_i = ||w_i||^2
    d = (W.pow(2)).sum(dim=0)                       # (T,)
    b2p = (d.pow(2)).mean()

    # ååº¦æ£€éªŒ
    df_skew = p*(p+1)*(p+2)//6
    skew_stat = T * b1p / 6.0                       # æ ‡é‡å¼ é‡

    # â€”â€” å…³é”®ä¿®å¤ï¼šåˆ†å¸ƒå‚æ•°å’Œ value æ”¾åˆ°åŒä¸€ deviceï¼›CUDA ä¸Šç”¨ float32 åš special å‡½æ•°æ›´ç¨³ â€”â€”
    cdf_dtype = torch.float32 if device.type == "cuda" else dtype
    chi2 = torch.distributions.Chi2(
        torch.tensor(df_skew, device=device, dtype=cdf_dtype)
    )
    skew_p = (1.0 - chi2.cdf(skew_stat.to(cdf_dtype).clamp_min(0))).item()

    # å³°åº¦æ£€éªŒï¼ˆæ­£æ€è¿‘ä¼¼ï¼‰
    Eb2 = p*(p+2)
    Varb2 = 8.0*p*(p+2)/T
    z_kurt = (b2p - Eb2) / (Varb2**0.5 + 1e-12)

    norm0 = torch.distributions.Normal(
        loc=torch.tensor(0.0, device=device, dtype=cdf_dtype),
        scale=torch.tensor(1.0, device=device, dtype=cdf_dtype),
    )
    kurt_p = (2.0 * (1.0 - norm0.cdf(z_kurt.to(cdf_dtype).abs()))).item()

    return dict(
        skew_stat=float(skew_stat),
        skew_p=float(skew_p),
        kurt_stat=float(z_kurt),
        kurt_p=float(kurt_p)
    )


# ------------------------- èƒ½é‡è·ç¦»æ£€éªŒï¼ˆTorch ç‰ˆï¼‰ -------------------------
@torch.no_grad()
def _pdist_avg_torch(A: Tensor, B: Tensor) -> Tensor:
    # è¿”å›å¹³å‡ä¸¤ä¸¤æ¬§æ°è·ç¦» E||A-B||
    # æ³¨æ„ï¼šcdist éœ€è¦è¾ƒå¤§æ˜¾å­˜ï¼ŒT å¾ˆå¤§æ—¶å¯æ”¹æˆåˆ†å—
    return torch.cdist(A, B).mean()

@torch.no_grad()
def energy_distance_torch(A: Tensor, B: Tensor) -> Tensor:
    return 2*_pdist_avg_torch(A, B) - _pdist_avg_torch(A, A) - _pdist_avg_torch(B, B)

@torch.no_grad()
def energy_gaussian_test_torch(Y: Tensor, B: int = 200, generator=None, jitter: float = 1e-6) -> dict:
    """
    ä¸æ‹ŸåˆåŒå‡å€¼/åæ–¹å·®é«˜æ–¯æ ·æœ¬æ¯”è¾ƒçš„èƒ½é‡è·ç¦»ç½®æ¢æ£€éªŒï¼ˆTorch ç‰ˆï¼‰
    Y: (T, k)
    """
    T, k = Y.shape
    mu = Y.mean(dim=0)
    C = ((Y - mu).T @ (Y - mu)) / (T - 1)
    C = C + jitter * torch.eye(k, dtype=DTYPE, device=Y.device)

    mvn = MultivariateNormal(loc=mu, covariance_matrix=C)
    Yg = mvn.sample((T,))                           # (T, k)

    E_obs = energy_distance_torch(Y, Yg)
    Z = torch.cat([Y, Yg], dim=0)                   # (2T, k)
    idx = torch.arange(2*T, device=Y.device)

    cnt = 0
    for _ in range(B):
        if generator is None:
            perm = idx[torch.randperm(2*T, device=Y.device)]
        else:
            perm = idx[torch.randperm(2*T, generator=generator, device=Y.device)]
        Y1 = Z[perm[:T]]
        Y2 = Z[perm[T:]]
        if energy_distance_torch(Y1, Y2) >= E_obs:
            cnt += 1
    p = (cnt + 1) / (B + 1)
    return dict(E_obs=float(E_obs), p=float(p))

# ------------------------- éšæœºå­ç©ºé—´ + å¤šå…ƒæ£€éªŒï¼ˆTorch ç‰ˆï¼‰ -------------------------
@torch.no_grad()
def random_subspace_multivariate_tests_torch(
    noise_TXY: torch.Tensor,
    k_list=(5, 10, 20, 50),
    r=100,
    B=50,
    standardize=True,
    seed=0
):
    """
    noise_TXY: torch.Tensor (T, X, Y)
    åœ¨æ¯ä¸ª k çš„å¾ªç¯ä¸­åŠ å…¥ tqdm è¿›åº¦æ¡ã€‚
    """
    assert noise_TXY.ndim == 3, "noise å¿…é¡»æ˜¯ä¸‰ç»´ (T, X, Y)ã€‚"
    device = noise_TXY.device
    gen = torch.Generator(device=device)
    gen.manual_seed(seed)

    T, X, Y = noise_TXY.shape
    data = noise_TXY.reshape(T, -1).to(torch.float64)
    D = data.shape[1]
    if standardize:
        data = _standardize_columns_torch(data)

    summary = {}
    for k in k_list:
        if not (k <= D and k < T):
            summary[k] = dict(skipped=True, reason=f"k={k} éœ€æ»¡è¶³ k <= D ä¸” k < Tï¼›å®é™… T={T}, D={D}")
            continue

        mardia_pass = 0
        energy_pass = 0
        mardia_p_pairs = []
        energy_pvals = []

        print(f"\nğŸ”¹ æ­£åœ¨æµ‹è¯•å­ç©ºé—´ç»´åº¦ k={k} ...")
        for _ in tqdm(range(r), desc=f"Subspace test k={k}", ncols=90):
            # éšæœº k ç»´æ­£äº¤å­ç©ºé—´
            Q = _random_orth_subspace_torch(D, k, generator=gen, device=device)
            Yk = data @ Q  # (T, k)

            # --- Mardia æ£€éªŒ ---
            mt = mardia_test_torch(Yk)
            mardia_ok = (mt["skew_p"] > 0.05) and (mt["kurt_p"] > 0.05)
            mardia_pass += int(mardia_ok)
            mardia_p_pairs.append((mt["skew_p"], mt["kurt_p"]))

            # --- èƒ½é‡è·ç¦»æ£€éªŒ ---
            et = energy_gaussian_test_torch(Yk, B=B, generator=gen)
            energy_ok = (et["p"] > 0.05)
            energy_pass += int(energy_ok)
            energy_pvals.append(et["p"])

        summary[k] = dict(
            skipped=False,
            r=r,
            mardia_pass_ratio=mardia_pass / r,
            mardia_p_values=torch.tensor(mardia_p_pairs, dtype=torch.float64, device=device).cpu().numpy(),
            energy_pass_ratio=energy_pass / r,
            energy_p_values=torch.tensor(energy_pvals, dtype=torch.float64, device=device).cpu().numpy(),
        )

    return dict(T=T, D=D, k_list=k_list, r=r, B=B, standardize=standardize, results=summary)

# ------------------------- éšæœºæŠ•å½±ï¼ˆTorch ç‰ˆï¼›1D æ­£æ€æ€§å¯é€‰ï¼‰ -------------------------
@torch.no_grad()
def random_projection_gaussian_test_torch(noise_TXYL: Tensor, level: int = 0, num_proj: int = 50, seed: int = 42):
    """
    ä¸ä½ åŸå‡½æ•°ç­‰ä»·ï¼Œä½†åœ¨ Torch ä¸Šå®ŒæˆæŠ•å½±ä¸æ ‡å‡†åŒ–ã€‚
    è¯´æ˜ï¼šä¸€ç»´æ­£æ€æ€§çš„å…·ä½“æ£€éªŒç»Ÿè®¡ï¼ˆå¦‚ Dâ€™Agostinoï¼‰ä»å¯è°ƒç”¨ SciPyï¼›è¿™é‡Œæ¼”ç¤ºåªè¿”å›æ ‡å‡†åŒ–åçš„æŠ•å½±ä¾›ä½ å¤–éƒ¨æ£€éªŒã€‚
    """
    device = noise_TXYL.device
    gen = torch.Generator(device=device).manual_seed(seed)

    # å…¼å®¹è¾“å…¥å½¢çŠ¶ï¼š (T, levels, X, Y) æˆ– (T, X, Y)ï¼ˆè‹¥å·²å…ˆ get_field å›ºå®š levelï¼‰
    if noise_TXYL.ndim == 4:
        T, L, X, Y = noise_TXYL.shape
        data = noise_TXYL[:, level].reshape(T, -1).to(DTYPE)
    elif noise_TXYL.ndim == 3:
        T, X, Y = noise_TXYL.shape
        data = noise_TXYL.reshape(T, -1).to(DTYPE)
    else:
        raise ValueError("noise éœ€è¦æ˜¯ (T, L, X, Y) æˆ– (T, X, Y)")

    D = data.shape[1]
    pvals = []  # å¦‚éœ€ 1D æ­£æ€æ£€éªŒï¼Œè¿™é‡Œå¯å›ä¼ ç»™ SciPyï¼›æ­¤å‡½æ•°ä¸»è¦è´Ÿè´£é«˜æ•ˆæŠ•å½±ä¸æ ‡å‡†åŒ–

    # æ‰¹é‡ç”Ÿæˆéšæœºæ–¹å‘å¯è¿›ä¸€æ­¥åŠ é€Ÿï¼›æ­¤å¤„ç®€æ´èµ·è§é€æ¬¡
    for _ in range(num_proj):
        w = torch.randn(D, dtype=DTYPE, device=device, generator=gen)
        w = w / (w.norm() + 1e-12)
        proj = (data @ w)
        proj = (proj - proj.mean()) / (proj.std(unbiased=True) + 1e-12)
        # ä½ å¯åœ¨å¤–éƒ¨å¯¹ proj.cpu().numpy() åš scipy.stats.normaltest
        pvals.append(float('nan'))

    return {
        "num_projections": num_proj,
        "p_values": np.array(pvals),
        "median_p_value": np.nan,
        "pass_ratio_gt_0_05": np.nan
    }


# 1) è¯»å–æ•°æ®ï¼ˆTorchï¼‰
sqg = SQGDataTorch('SQG.npy', 'inverted_SQG.npy', device='cuda')  # è‹¥æ—  GPU å¯çœç•¥ device

# 2) å–å‡ºä¸€ä¸ª level çš„æ—¶åºåœº (T, X, Y)
noise0 = sqg.get_field(dataset='noise', level=0, normalized=False)  # torch.Tensor

# 3) è·‘éšæœºå­ç©ºé—´ + å¤šå…ƒæ£€éªŒï¼ˆGPU ä¸Šä¼šå¾ˆå¿«ï¼ŒMardia å…¨åœ¨ Torch å†…å®Œæˆï¼‰
res = random_subspace_multivariate_tests_torch(
    noise0,
    k_list=(5, 10, 20, 50),
    r=100,          # å­ç©ºé—´æŠ½æ ·æ¬¡æ•°
    B=200,          # èƒ½é‡è·ç¦»ç½®æ¢æ¬¡æ•°ï¼ˆå¤§å°±æ…¢ï¼›å¯å…ˆ 50/100ï¼‰
    standardize=True,
    seed=0
)

# 4) è¯»ç»“æœ
for k in res["k_list"]:
    info = res["results"][k]
    if info["skipped"]:
        print(f"k={k} è·³è¿‡ï¼š{info['reason']}")
        continue
    print(f"\n[å­ç©ºé—´ç»´åº¦ k={k}]")
    print(f"  Mardia  é€šè¿‡ç‡: {info['mardia_pass_ratio']*100:.1f}%")
    print(f"  Energy  é€šè¿‡ç‡: {info['energy_pass_ratio']*100:.1f}%")
